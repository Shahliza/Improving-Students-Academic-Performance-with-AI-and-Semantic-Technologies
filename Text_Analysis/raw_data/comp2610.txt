Information theory studies the fundamental limits of the representation and transmission of information. 
This course provides an introduction to information theory, studying fundamental concepts such as probability, information, and entropy and examining their applications in the areas of data compression, coding, communications, pattern recognition and probabilistic inference.
Understand and apply fundamental concepts in information theory such as probability, entropy, information content and their inter-relationships.
Understand the principles of data compression.
Compute entropy and mutual information of random variables.
Implement and analyse basic coding and compression algorithms.
Understand the relationship of information theoretical principles and Bayesian inference in data modelling and pattern recognition.
Understand some key theorems and inequalities that quantify essential limitations on compression, communication and inference.
Know the basic concepts regarding communications over noisy channels.